{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 : Spatial Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we explore the measurement of spatial autocorrelation by Moran's index. \n",
    "\n",
    "We will use both _R_ in this notebook and a package called _GeoDa_ (installed on the lab computers) to do this. Each has advantages. We suggest you work in this notebook to the point where you begin to find the code involved a bit bewildering. It's OK if that happens: don't panic, just switch to _GeoDa_. \n",
    "\n",
    "Even if you don't get pushed past your tolerance for code, you are encouraged to also explore the application of these measures using _GeoDa_.\n",
    "\n",
    "Whichever tool you use to complete the lab, you will find the submission instructions and questions at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "First we have to import some packages for handling spatial data. We have used these before (in the Lab 0 notebook), except for `spdep` which implements various methods for exploring **spatial dependence** in data, one of which is Moran's _I_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(spdep)\n",
    "library(classInt)\n",
    "library(rgdal)\n",
    "library(RColorBrewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that's done, we can, move on to...\n",
    "\n",
    "## Read in the data and take a look at it\n",
    "Read the shape file from the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auck <- readOGR(\"data/ak-TB-ethnicity-0506.shp\", integer64=\"allow.loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means that the data are now all associated with an object called `auck`. We can see a summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(auck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows us that we have a number of data attributes, including `TB_CASES` and `TB_RATE` which record numbers of cases and rate (per 100,000 population) of tuberculosis in census area units (AUs) in Auckland, New Zealand.\n",
    "\n",
    "Spatial data has a 'geography' component and a 'data attributes' component. We can look more closely at the data part by splitting out the data into an _R_ data frame, and using the `head`() command to see the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data frame -> row and header of data, in \"tabular\" format\n",
    "#let's make df the dataframe\n",
    "df <- data.frame(auck)\n",
    "nrow(df)\n",
    "head(df, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data table is all very well, but since these are geographical data, what we really want to do is...\n",
    "\n",
    "## Exploring the data in maps\n",
    "\n",
    "As in the previous lab, we will make some choropleth maps to examine the various data of interest in this setting. To make this a bit less arduous, here is that simple choropleth mapping function from the previous notebook, which you can use to make maps of the different variables of interest. Make sure to run this cell, so that the `choro()` function that it defines is available in the rest of your session in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of a function to automate a series of commands and make a choropleth map\n",
    "choro <- function(sf, varname, nclasses=5, pal='Reds', sty='equal', ttl=varname) {\n",
    "    palette <- brewer.pal(nclasses, pal)\n",
    "    classes <- classIntervals(sf[[varname]], nclasses, style=sty)\n",
    "    colors <- findColours(classes, palette)\n",
    "    plot(sf, col=colors, lwd=0.2)\n",
    "    legend('top', ncol=3, legend=names(attr(colors, 'table')), fill=attr(colors, 'palette'), cex=0.8, bty='n')\n",
    "    title(ttl)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principally we want you to look at the tuberculosis rate (in cases per 100,000 population) `TB_RATE`,  and also at the different distributions of the four major New Zealand Census-defined ethnic groups, NZ European `EUR_P_06`, Māori `MAO_P_06`, Pasifika `PAC_P_06`, and Asian `ASI_P_06`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above function in the cell below, to map the tuberculosis rate.\n",
    "\n",
    "Don't forget that you have options for changing the map colors (`pal`), the number of classes (`nclasses`) and the classification method (`sty`) in this map and others you make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put a line of code here to map the tuberculosis rate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cell below to map all four of the major population groups. idea you might explore is to make all four of the ethnicity/race distribution maps in single display, by first issuing the `par(mfrow=c(2,2))` command, which will set up the display area for a 2 by 2 grid of maps. Then make four distinct maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line sets up the graphic display for a two by two array of plots\n",
    "# with narrower margins of 0.1 of the overall display area\n",
    "par(mfrow=c(2,2), mai=rep(0.1,4))\n",
    "# write a line of code to make a map\n",
    "# write a line to make another map\n",
    "# and another\n",
    "# and then a fourth one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing the data\n",
    "Keep in mind that you can also graph data, if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(auck$ASI_P_06, labels=T, main=\"Percent Asian (census-defined), 2006\", xlab=\"Percent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some background on Auckland's diverse population\n",
    "It's worth recognizing the specificity of these groups to the New Zealand and particularly the Auckland setting. \n",
    "\n",
    "Māori are the population indigenous to New Zealand before European arrival in the 19th century. Pasifika reflect Auckland's place as 'the capital of Polynesia', with more people of Pacific Island heritage than anywhere in the world with the possible exception of Los Angeles (a metropolis 12 to 15 times more populous).  See for example, this footage of crowds of Aucklanders greeting the arrival of the Samoan (https://www.youtube.com/watch?v=NABfXFHumHg) and Tongan (https://www.youtube.com/watch?v=qyu646wHw08) rugby teams before the 2011 Rugby World Cup in Auckland.  Pasifika have been a substantial presence in Auckland since the 1950s when many arrived as 'guest workers'.  \n",
    "\n",
    "More recently, Auckland, in common with Pacific Rim cities (including in California) has seen the rapid growth of large immigrant communities from across Asia, but especially East Asia, become a firmly established component of the city's greater than 40% foreign-born population.\n",
    "\n",
    "As in the US, the 'Asian' population category is ridiculously broad, including South Asian (i.e. India-Pakistan), Chinese, and East Asian (Korea, Vietnam, etc.)  How race and ethnicity are defined in census terms is a vexed question, that varies from place to place.  For our present purpose, of note is that Māori and Pasifika populations in New Zealand are more socioeconomically challenged than the population in general, and that the Asian population are more likely to be recent immigrants than other segments of the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The focus of this lab is on measuring spatial autocorrelation. We are going to do this with the aim of identifying where the most dense clear clusters ('high-high') of high tuberculosis rates are to be found based on the data available. We will start with a simple autocorrelation analysis, and then proceed to the more complex business of local Moran's analysis, which is what we need to identify cluster locations.\n",
    "\n",
    "The goal then is to relate the cluster locations, at least qualitatively to the different population distributions (mapped in the previous sections) and answer some questions that follow, at the end of the notebook.\n",
    "\n",
    "We make no representation that the steps in this notebook (or using GeoDa) represent a thorough analysis of the topic at hand, but they do provide a sense of how getting a handle on spatial patterns can be generative of interesting perspectives and prompt further questions.\n",
    "\n",
    "You will recall from lectures, that there are two aspects to measuring spatial autocorrelation, the first being 'nearness', so we will look at this first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearness - setting up the neighborhood structure\n",
    "Here we will use the simplest possible definition of neighbors based on polygon contiguity. More elaborate concepts of 'nearness' can be explored using _GeoDa_, or if you are feeling brave, by delving into the [`spdep` package documentation](https://www.rdocumentation.org/packages/spdep/versions/0.7-4).\n",
    "\n",
    "We make a neighbors object using the `poly2nb` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queen = False option means at least two boundary points must be \n",
    "# with the conventional name of a ‘rook’ relationship.\n",
    "nb <- poly2nb(auck, row.names=auck$FIRST_CAU_, queen=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get an idea of what is in the `nb` object by looking using the `summary()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure you have some idea of what is going on here, consider the following question:\n",
    "\n",
    "**How many regions are there with no links?**\n",
    "\n",
    "If you are unsure, ask!\n",
    "\n",
    "We can also check what the neighborhoods look like, by plotting `nb` on top of a basemap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(auck, col='gray', border='white', lwd=0.35)\n",
    "plot(nb, coordinates(auck), col='red', cex=0.5, lwd=0.5, add=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moran's *I* in equation form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$I = \\frac{n}{\\sum_{i=1}^n (y_i - \\bar{y})^2} \\frac{\\sum_{i=1}^n \\sum_{j=1}^n w_{ij}(y_i - \\bar{y})(y_j - \\bar{y})}{\\sum_{i=1}^n \\sum_{j=1}^n w_{ij}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first see what manual computation of Moran's I looks like.\n",
    "# This part is optional, but feel free to uncomment the lines \n",
    "# needed to run the manual calculation\n",
    "\n",
    "# 1. n is the number of observations (length of our dataset)\n",
    "# n <- length(auck)\n",
    "\n",
    "# 2. we set y to the column of PC_ASIAN, then we get the mean.\n",
    "# y <- auck$PC_ASIAN\n",
    "# ybar <- mean(y)\n",
    "\n",
    "# 3. find the difference between y and ybar(the mean)\n",
    "# dy <- y - ybar\n",
    "# yi <- rep(dy, each=n)\n",
    "# yj <- rep(dy)\n",
    "# yiyj <- yi * yj\n",
    "\n",
    "# pm <- matrix(yiyj, ncol=n)\n",
    "\n",
    "# pmw <- pm * wm\n",
    "\n",
    "# spmw <- sum(pmw)\n",
    "\n",
    "# smw <- sum(wm)\n",
    "# sw  <- spmw / smw\n",
    "# vr <- n / sum(dy^2)\n",
    "# MI <- vr * sw\n",
    "\n",
    "# 4. Morans I\n",
    "# cat(\"Moran's I is\", MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a weights object so that we \n",
    "# can use it with a less manual way of computing moran's i\n",
    "lw <- nb2listw(nb, style=\"W\", zero.policy=TRUE)\n",
    "print(lw, zero.policy=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(lw, zero.policy=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m_scatterplot <- function (sf, varname, listweights, ttl='', linecol='red') {\n",
    "    \n",
    "scaled_col <<- paste('s', varname, sep='')\n",
    "lagged_col <<- paste('lag_', varname, sep='')\n",
    "print(scaled_col)\n",
    "print(lagged_col)\n",
    "\n",
    "sf[[scaled_col]] <- scale(sf[[varname]]) \n",
    "    \n",
    "sf[[lagged_col]] <- lag.listw(listweights, sf[[scaled_col]], zero.policy=TRUE)\n",
    "    \n",
    "plot(x=sf[[scaled_col]], y=sf[[lagged_col]], xlab=scaled_col, ylab=lagged_col, main=ttl)\n",
    "    \n",
    "abline(h=0, v=0)\n",
    "best_fit_line <- lm(sf[[lagged_col]] ~ sf[[scaled_col]])\n",
    "abline(best_fit_line, lty=2, lwd=1, col=linecol)\n",
    "    \n",
    "#Note that the slope of the regression line \n",
    "# is nearly the same as Moran's I\n",
    "coefficients(best_fit_line)[2]\n",
    "    \n",
    "# Save new columns into the shapefile\n",
    "assign('auck',sf, envir=.GlobalEnv)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function to make the plot\n",
    "m_scatterplot(auck, 'ASI_P_06', lw, ttl='Moran Scatterplot Percent Asian', linecol='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How did we change our shapefile?\n",
    "\n",
    "Let's look at the table format again, with the head() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head(auck@data, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran(auck$ASI_P_06, lw, n=length(lw$neighbours), S0=Szero(lw), NAOK=TRUE, zero.policy=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran.test(auck$ASI_P_06, lw, randomisation=FALSE, zero.policy=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmc <- moran.mc(auck$ASI_P_06, lw, nsim=999, zero.policy=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(mmc$res, main=\"Histogram of results from permutation\", xlab=\"Moran's index\")\n",
    "abline(v=mmc$statistic, col='red', lty=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Local Moran’s I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Moran is defined as:\n",
    "\n",
    "$I_i = \\frac{(x_i-\\bar{x})}{{\\sum_{k=1}^{n}(x_k-\\bar{x})^2}/(n-1)}{\\sum_{j=1}^{n}w_{ij}(x_j-\\bar{x})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the localmoran function instead of moran\n",
    "# let's title our results \"locm_asi_p_o6\" for clarity\n",
    "locm_asi_p_06 <- localmoran(auck$ASI_P_06, lw, alternative=\"two.sided\")\n",
    "summary(locm_asi_p_06, NAOK = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What exactly do the above numbers mean?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print out the locm dataframe, which is what locm (local moran)\n",
    "# gives back to us\n",
    "number_of_rows <- nrow(locm_asi_p_06) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many number of rows are there? \n",
    "How does this compare to the number of rows in the shapefile?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the output of locm look like? \n",
    "We'll just look at the first 10 rows to get a quick sense of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(locm_asi_p_06, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fortunately** there is some very nice documentation on locm, especially on the columns it outputs.\n",
    "\n",
    "It's here: https://www.rdocumentation.org/packages/spdep/versions/0.7-4/topics/localmoran\n",
    "\n",
    "`Ii` is the `local moran statistic`\n",
    "\n",
    "`E.Ii` is the `expectation of local moran statistic`\n",
    "\n",
    "`Var.Ii` is the `variance of local moran statistic`\n",
    "\n",
    "`Z.Ii` is the `standard deviate of local moran statistic`\n",
    "\n",
    "`Pr()` is the `p-value of local moran statistic`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LISA Cluster map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From your readings about local moran, we'll want to make some quadrants from the scatterplot, in order to make maps that indicate clustering.\n",
    "\n",
    "These quadrants will go into Local Indicators of Spatial Association (LISA) Cluster maps.\n",
    "\n",
    "Local Indicators of Spatial Association (LISA) tests for regional clustering and the presence of significant spatial clusters or outliers.\n",
    "\n",
    "The LISA Significance Map shows significant results by tract. \n",
    "\n",
    "The LISA Cluster Map shows how the attributes cluster.  In the example below using the specific color gradient, the red color shows tracts where high rate cluster with high rates, and blue shows where low rates cluster with low rates.  \n",
    "\n",
    "- High-high and low-low = spatial clusters\n",
    "- High-low and low-high = spatial outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make some quadrants from the data for our map. First, let's think back to the scatterplot.\n",
    "\n",
    "If you think back to the scatterplot, there's essentially 4 quadrants in the scatterplot.\n",
    "\n",
    "|- | + |\n",
    "|---|---|\n",
    "|  4  |  1  |\n",
    "|  2   | 3   |\n",
    "\n",
    "scaled_col is the x-axis\n",
    "lagged_col is the y-axis\n",
    "\n",
    "- 1 is where scaled_col is greater than 0, lagged_col is greater than 0, high-high\n",
    "- 2 is where scaled_col is less than 0, lagged_col is less than 0, low-low\n",
    "- 3 is where scaled_col is greater than zero and lagged_col is less than 0, high-low\n",
    "- 4 is where scaled_col is less than 0, lagged_col is greater than 0, low-high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the moran plot quadrant for each \n",
    "# observation to make the cluster map\n",
    "\n",
    "lisa_quadrant_cluster <- function (sf, locm_table, data_col, scaled_col, lagged_col, sig=0.05) {\n",
    "    # First, let's make an empty QUAD_SIG data column for the data we're looking at, in the shapefile\n",
    "    quad_sig_col <<- paste('QUAD_SIG_', data_col, sep='')\n",
    "    \n",
    "    sf[[quad_sig_col]] <- NA\n",
    "    \n",
    "    # Then let's assign quadrants\n",
    "    sf[[quad_sig_col]][(sf[[scaled_col]] >= 0 & sf[[lagged_col]] >= 0) & (locm_table[, 5] <= sig)] <- 1\n",
    "    sf[[quad_sig_col]][(sf[[scaled_col]] <= 0 & sf[[lagged_col]] <= 0) & (locm_table[, 5] <= sig)] <- 2\n",
    "    sf[[quad_sig_col]][(sf[[scaled_col]] >= 0 & sf[[lagged_col]] <= 0) & (locm_table[, 5] <= sig)] <- 3\n",
    "    sf[[quad_sig_col]][(sf[[scaled_col]] <= 0 & sf[[lagged_col]] >= 0) & (locm_table[, 5] <= sig)] <- 4\n",
    "    sf[[quad_sig_col]][(sf[[scaled_col]] <= 0 & sf[[lagged_col]] >= 0) & (locm_table[, 5] <= sig)] <- 5\n",
    "    #5 are non significant observations\n",
    "    assign('auck',sf, envir=.GlobalEnv)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lisa_quadrant_cluster(auck, locm_asi_p_06, 'ASI_P_06','sASI_P_06', 'lag_ASI_P_06', sig=0.05)\n",
    "\n",
    "#head(auck@data,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to make our first LISA cluster map\n",
    "local_moran_cluster_map <- function (sf, \n",
    "                                     quad_sig_column, \n",
    "                                     breaks=c(1,2,3,4,5), \n",
    "                                     labels, colors, ttl=\"Local Moran's I\") {\n",
    "    \n",
    "    # Set the corresponding labels for the thematic map classes\n",
    "    numberOfIntervals <- findInterval(sf[[quad_sig_column]], breaks)\n",
    "\n",
    "    # Generate the map\n",
    "    plot(auck, col = pal[numberOfIntervals])\n",
    "    mtext(ttl, cex = 1.5, side =3, line = 1)\n",
    "    legend(\"topleft\", legend = labels, fill = pal, bty = \"n\")\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the labeling for the map legend. These are the high-high, low-low etc \n",
    "# classes we calculated from the quadrants ealier.\n",
    "labeling <- c(\"High-High\", \"Low-Low\", \"High-Low\", \"Low-High\", \"Not Signif.\")\n",
    "\n",
    "# Set the breaks for the thematic map classes\n",
    "# We use the seq function to generation a sequence from 1-5, going up by 1.\n",
    "num_breaks <- 1:6\n",
    "\n",
    "# Define color swatches\n",
    "pal <- c(\"red\", \"blue\", \"lightpink\", \"skyblue2\", \"white\")\n",
    "\n",
    "\n",
    "local_moran_cluster_map(auck, 'QUAD_SIG_ASI_P_06', num_breaks, labeling, colors, ttl=\"Local Moran's I\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### LISA Significance map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The significance map made from the p values that localmoran() gave us.\n",
    "# Reminder that the p values (significance) is column number 5 in locm\n",
    "# We'll want to copy over the p-values from the locm results to our shapefile first\n",
    "# So that we can map the values by color\n",
    "\n",
    "\n",
    "local_moran_sig_map <- function (sf, \n",
    "                                 locm_table, \n",
    "                                 new_column_name, \n",
    "                                 plabels, breakpoints, num_breaks=5, \n",
    "                                 ttl=\"LISA Significance Map\",\n",
    "                                 palcolors=\"Greens\") {\n",
    "    # Make a column in auck data that has NA\n",
    "    sf[[new_column_name]] <- NA\n",
    "    \n",
    "    # Populate LOCM_P with the results from locm function\n",
    "    sf[[new_column_name]] <- locm_table[,5]\n",
    "    sf[[new_column_name]]\n",
    "    classes <- classIntervals(sf[[new_column_name]], num_breaks, style=\"fixed\", fixedBreaks=breakpoints)\n",
    "    \n",
    "    #How many items do we have in each of our class intervals?\n",
    "    print(classes)\n",
    "    \n",
    "    palette <- rev(brewer.pal(num_breaks, palcolors))\n",
    "    colors <- findColours(classes, palette)\n",
    "\n",
    "    # Generate the map\n",
    "    plot(auck, col = colors, lwd=0.2, main=ttl)\n",
    "\n",
    "    legend(\"topleft\", legend = plabels, fill = palette, bty = \"n\")\n",
    "    assign('auck',sf, envir=.GlobalEnv)\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_labels <- c(\"p<=0.0001\", \"p<=0.001\",\"p<=0.01\", \"p<=0.05\",\"Not Significant\")\n",
    "pval_fixed_breaks <- c(1,0.05,0.01,0.001,0.0001,0)\n",
    "\n",
    "#head(auck@data, n=10)\n",
    "local_moran_sig_map(auck,\n",
    "                    locm_asi_p_06,\n",
    "                    'LOCM_ASI_P_06', \n",
    "                    pval_labels, \n",
    "                    pval_fixed_breaks, \n",
    "                    5, ttl=\"LISA Significance Map\", \"Greens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Questions + Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Determine the Moran’s I statistic for:\n",
    "    - TB Rates \n",
    "    - Maori census groupings\n",
    "    - Asian census groupings\n",
    "    - Pacific Islander groupings\n",
    "    - European groupings. \n",
    "  \n",
    "2. For one (you choose) of the four major groupings perform the Univariate Local Moran’s\n",
    "analysis. You should produce a Moran scatter plot, Significance map and Cluster map for this\n",
    "analysis, and also a standard map (choose the map type you consider most informative)\n",
    "\n",
    "3. Write a short report addressing the questions below:\n",
    "\n",
    "    **Q1**:\n",
    "\n",
    "    Compile a table of the Univariate Moran’s I results for each of the four major census groups. Which is most ‘aggregated’ based on these results? Do you think this result is very meaningful? Explain your answer with respect only to the statistical results, not the geographical distributions. \n",
    "\n",
    "    **Q2**:\n",
    "\n",
    "    What correlation are there between the TB Rates and the census groupings? Are the TB Rates geographically clustered? \n",
    "\n",
    "    **Q3**:\n",
    "\n",
    "    What changes to the Moran’s I approach might identify the difference among the groups more effectively? \n",
    "    [Hint: This is not an easy question, and you are not expected to come up with a definitive answer. Think about (among other things): scale, the census polygons being used, the total populations of each group, and how we are considering ‘near’ when we use polygon contiguity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
